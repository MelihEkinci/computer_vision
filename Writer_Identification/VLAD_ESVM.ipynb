{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import skeleton_with_bonus\n",
    "from skeleton_with_bonus import loadRandomDescriptors,loadRandomDescriptors_v3, getFiles, dictionary,assignments,vlad,generate_multiple_codebooks_v2,multi_vlad,generate_multiple_codebooks,apply_pca,distances,evaluate, train_svm, exemplar_classification, exemplar_classification_parallel,computeDescs,getFiles_v2,loadRandomDescriptors_v2,compute_and_save_desc\n",
    "import os\n",
    "import _pickle as cPickle\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_train = '/Users/melihekinci/Documents/FAU_Courses/ThirdSemester/Computer Vision/Week 3/train'\n",
    "suffix = '_SIFT_patch_pr.pkl.gz'\n",
    "labels_train = 'icdar17_labels_train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#train: 1182\n"
     ]
    }
   ],
   "source": [
    "files_train, labels_train = getFiles(in_train, suffix, labels_train)\n",
    "print('#train: {}'.format(len(files_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 77.00it/s]\n"
     ]
    }
   ],
   "source": [
    "descriptors = loadRandomDescriptors(files_train, max_descriptors=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 64)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('mus.pkl.gz'):\n",
    "    descriptors = loadRandomDescriptors(files_train, max_descriptors=500000)\n",
    "    print('> loaded {} descriptors:'.format(len(descriptors)))\n",
    "\n",
    "    # cluster centers\n",
    "    print('> compute dictionary')\n",
    "    mus = dictionary(descriptors, n_clusters=100)\n",
    "    with gzip.open('mus.pkl.gz', 'wb') as fOut:\n",
    "        cPickle.dump(mus, fOut, -1)\n",
    "else:\n",
    "    with gzip.open('mus.pkl.gz', 'rb') as f:\n",
    "        mus = cPickle.load(f)\n",
    "print(mus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> compute VLAD for test\n",
      "#test: 3600\n",
      "> evaluate\n",
      "Top-1 accuracy: 0.8197222222222222 - mAP: 0.6283903541081468\n"
     ]
    }
   ],
   "source": [
    "gamma = 1\n",
    "gmp = False\n",
    "in_test = '/Users/melihekinci/Documents/FAU_Courses/ThirdSemester/Computer Vision/Week 3/test'\n",
    "suffix = '_SIFT_patch_pr.pkl.gz'\n",
    "labels_test = 'icdar17_labels_test.txt'\n",
    "powernorm = True\n",
    "\n",
    "print('> compute VLAD for test')\n",
    "files_test, labels_test = getFiles(in_test, suffix,\n",
    "                                    labels_test)\n",
    "print('#test: {}'.format(len(files_test)))\n",
    "fname = 'enc_test_gmp{}.pkl.gz'.format(gamma) if gmp else 'enc_test.pkl.gz'\n",
    "if not os.path.exists(fname):\n",
    "    enc_test = vlad(files_test, mus, powernorm,gamma,gmp)\n",
    "    with gzip.open(fname, 'wb') as fOut:\n",
    "        cPickle.dump(enc_test, fOut, -1)\n",
    "else:\n",
    "    with gzip.open(fname, 'rb') as f:\n",
    "        enc_test = cPickle.load(f)\n",
    "        \n",
    "print('> evaluate')\n",
    "evaluate(enc_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> compute VLAD for train\n",
      "#train: 1182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1182/1182 [00:21<00:00, 56.00it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parameters for VLAD computation\n",
    "n_clusters = 100  # Example number of clusters for k-means\n",
    "max_descriptors = 500000  # Example max descriptors for MiniBatchKMeans\n",
    "C = 1000  # Regularization parameter for SVM\n",
    "gamma=900\n",
    "powernorm=True\n",
    "gmp=False\n",
    "\n",
    "# Paths for input data\n",
    "in_train = '/Users/melihekinci/Documents/FAU_Courses/ThirdSemester/Computer Vision/Week 3/train'\n",
    "suffix = '_SIFT_patch_pr.pkl.gz'  # Suffix for your training files\n",
    "labels_train = 'icdar17_labels_train.txt'\n",
    "\n",
    "# Compute or load the VLAD encodings for training data\n",
    "enc_train_file = 'enc_train_gmp_{}.pkl.gz'\n",
    "if not os.path.exists(enc_train_file):\n",
    "    print('> compute VLAD for train')\n",
    "    files_train, labels_train = getFiles(in_train, suffix, labels_train)\n",
    "    print('#train: {}'.format(len(files_train)))\n",
    "    enc_train = vlad(files_train, mus, powernorm,gamma,gmp)\n",
    "    with gzip.open(enc_train_file, 'wb') as fOut:\n",
    "        cPickle.dump(enc_train, fOut, -1)\n",
    "else:\n",
    "    with gzip.open(enc_train_file, 'rb') as f:\n",
    "        enc_train = cPickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> evaluate VLAD encodings\n",
      "Top-1 accuracy: 0.8211111111111111 - mAP: 0.6303366667827087\n"
     ]
    }
   ],
   "source": [
    "# Evaluate VLAD encodings\n",
    "print('> evaluate VLAD encodings')\n",
    "evaluate(enc_train, labels_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> compute E-SVM for test\n"
     ]
    }
   ],
   "source": [
    "# With parallelized\n",
    "print('> compute E-SVM for test')\n",
    "enc_train = np.array(enc_train) if isinstance(enc_train, list) else enc_train\n",
    "enc_test = np.array(enc_test) if isinstance(enc_test, list) else enc_test\n",
    "new_encs_test = exemplar_classification_parallel(enc_train, enc_test,C_value=1000, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> evaluate E-SVM encodings\n",
      "Top-1 accuracy: 0.8852777777777778 - mAP: 0.7526401045072001\n"
     ]
    }
   ],
   "source": [
    "# Optionally, evaluate the new E-SVM encodings\n",
    "print('> evaluate E-SVM encodings')\n",
    "evaluate(new_encs_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e - Extracting own features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptors for all images have been computed and saved in the new directory.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    image_directory = '/Users/melihekinci/Documents/FAU_Courses/ThirdSemester/Computer Vision/Week 3/icdar2017-training-binary'\n",
    "    new_directory = '/Users/melihekinci/Documents/FAU_Courses/ThirdSemester/Computer Vision/Week 3/icdar2017-training-binary/train_new'\n",
    "    if not os.path.exists(new_directory):\n",
    "        os.makedirs(new_directory)\n",
    "\n",
    "    # Prepare a list of arguments for the function\n",
    "    file_paths = [(os.path.join(image_directory, f), new_directory) \n",
    "                  for f in os.listdir(image_directory) \n",
    "                  if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "    # Use multiprocessing to process files in parallel\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        pool.starmap(compute_and_save_desc, file_paths)\n",
    "\n",
    "    print(\"Descriptors for all images have been computed and saved in the new directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    image_directory = '/Users/melihekinci/Documents/FAU_Courses/ThirdSemester/Computer Vision/Week 3/ScriptNet-HistoricalWI-2017-binarized'\n",
    "    new_directory = '/Users/melihekinci/Documents/FAU_Courses/ThirdSemester/Computer Vision/Week 3/ScriptNet-HistoricalWI-2017-binarized/test_new'\n",
    "    if not os.path.exists(new_directory):\n",
    "        os.makedirs(new_directory)\n",
    "\n",
    "    # Prepare a list of arguments for the function\n",
    "    file_paths = [(os.path.join(image_directory, f), new_directory) \n",
    "                  for f in os.listdir(image_directory) \n",
    "                  if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "    # Use multiprocessing to process files in parallel\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        pool.starmap(compute_and_save_desc, file_paths)\n",
    "\n",
    "    print(\"Descriptors for all images have been computed and saved in the new directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_train='/Users/melihekinci/Documents/FAU_Courses/ThirdSemester/Computer Vision/Week 3/icdar2017-training-binary/train_new'\n",
    "suffix='.desc'\n",
    "labels_train = 'icdar17_labels_train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#train: 1182\n"
     ]
    }
   ],
   "source": [
    "files_train, labels_train = getFiles_v2(in_train, suffix, labels_train)\n",
    "print('#train: {}'.format(len(files_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 53.76it/s]\n"
     ]
    }
   ],
   "source": [
    "descriptors = loadRandomDescriptors_v2(files_train, max_descriptors=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(488415, 128)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 128)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('mus_new.pkl.gz'):\n",
    "    descriptors = loadRandomDescriptors(files_train, max_descriptors=500000)\n",
    "    print('> loaded {} descriptors:'.format(len(descriptors)))\n",
    "\n",
    "    # cluster centers\n",
    "    print('> compute dictionary')\n",
    "    mus_new = dictionary(descriptors, n_clusters=100)\n",
    "    with gzip.open('mus_new.pkl.gz', 'wb') as fOut:\n",
    "        cPickle.dump(mus_new, fOut, -1)\n",
    "else:\n",
    "    with gzip.open('mus_new.pkl.gz', 'rb') as f:\n",
    "        mus_new = cPickle.load(f)\n",
    "print(mus_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> compute VLAD for test\n",
      "#test: 3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3600/3600 [01:37<00:00, 36.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> evaluate\n",
      "Top-1 accuracy: 0.8227777777777778 - mAP: 0.6329760064760036\n"
     ]
    }
   ],
   "source": [
    "gamma = 1\n",
    "gmp = False\n",
    "in_test = '/Users/melihekinci/Documents/FAU_Courses/ThirdSemester/Computer Vision/Week 3/ScriptNet-HistoricalWI-2017-binarized/test_new'\n",
    "suffix = '.desc'\n",
    "labels_test = 'icdar17_labels_test.txt'\n",
    "powernorm = False\n",
    "\n",
    "print('> compute VLAD for test')\n",
    "files_test, labels_test = getFiles(in_test, suffix,\n",
    "                                    labels_test)\n",
    "print('#test: {}'.format(len(files_test)))\n",
    "fname = 'enc_test_new_gmp{}.pkl.gz'.format(gamma) if gmp else 'enc_test_new.pkl.gz'\n",
    "if not os.path.exists(fname):\n",
    "    enc_test_new = vlad(files_test, mus_new, powernorm)\n",
    "    with gzip.open(fname, 'wb') as fOut:\n",
    "        cPickle.dump(enc_test_new, fOut, -1)\n",
    "else:\n",
    "    with gzip.open(fname, 'rb') as f:\n",
    "        enc_test_new = cPickle.load(f)\n",
    "        \n",
    "print('> evaluate')\n",
    "evaluate(enc_test_new, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> compute VLAD for train\n",
      "#train: 1182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1182 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1182/1182 [00:31<00:00, 37.41it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parameters for VLAD computation\n",
    "n_clusters = 100  # Example number of clusters for k-means\n",
    "max_descriptors = 500000  # Example max descriptors for MiniBatchKMeans\n",
    "C = 1000  # Regularization parameter for SVM\n",
    "\n",
    "# Paths for input data\n",
    "in_train = '/Users/melihekinci/Documents/FAU_Courses/ThirdSemester/Computer Vision/Week 3/icdar2017-training-binary/train_new'\n",
    "suffix = '.desc'  # Suffix for your training files\n",
    "labels_train = 'icdar17_labels_train.txt'\n",
    "\n",
    "# Compute or load the VLAD encodings for training data\n",
    "enc_train_file = 'enc_train_new.pkl.gz'\n",
    "if not os.path.exists(enc_train_file):\n",
    "    print('> compute VLAD for train')\n",
    "    files_train, labels_train = getFiles(in_train, suffix, labels_train)\n",
    "    print('#train: {}'.format(len(files_train)))\n",
    "    enc_train_new = vlad(files_train, mus_new, powernorm)\n",
    "    with gzip.open(enc_train_file, 'wb') as fOut:\n",
    "        cPickle.dump(enc_train_new, fOut, -1)\n",
    "else:\n",
    "    with gzip.open(enc_train_file, 'rb') as f:\n",
    "        enc_train_new = cPickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> compute E-SVM for test\n",
      "> evaluate E-SVM encodings\n",
      "Top-1 accuracy: 0.8813888888888889 - mAP: 0.744585942886534\n"
     ]
    }
   ],
   "source": [
    "# With parallelized\n",
    "print('> compute E-SVM for test')\n",
    "enc_train_new = np.array(enc_train_new) if isinstance(enc_train_new, list) else enc_train_new\n",
    "enc_test_new = np.array(enc_test_new) if isinstance(enc_test_new, list) else enc_test_new\n",
    "new_encs_test = exemplar_classification_parallel(enc_train_new, enc_test_new,C_value=1000, n_jobs=-1)\n",
    "# Optionally, evaluate the new E-SVM encodings\n",
    "print('> evaluate E-SVM encodings')\n",
    "evaluate(new_encs_test, labels_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f - Generalized Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> compute VLAD for test\n",
      "#test: 3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3600/3600 [07:37<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> evaluate\n",
      "Top-1 accuracy: 0.835 - mAP: 0.6450024517439594\n"
     ]
    }
   ],
   "source": [
    "gamma = 900\n",
    "gmp = True\n",
    "powernorm = True\n",
    "in_test = '/Users/melihekinci/Documents/FAU_Courses/ThirdSemester/Computer Vision/Week 3/ScriptNet-HistoricalWI-2017-binarized/test_new'\n",
    "suffix = '.desc'\n",
    "labels_test = 'icdar17_labels_test.txt'\n",
    "\n",
    "\n",
    "\n",
    "print('> compute VLAD for test')\n",
    "files_test, labels_test = getFiles(in_test, suffix,\n",
    "                                    labels_test)\n",
    "print('#test: {}'.format(len(files_test)))\n",
    "fname = 'enc_test_new_gmp{}.pkl.gz'.format(gamma) if gmp else 'enc_test_new.pkl.gz'\n",
    "if not os.path.exists(fname):\n",
    "    enc_test_new = vlad(files_test, mus_new,powernorm, gamma,gmp)\n",
    "    with gzip.open(fname, 'wb') as fOut:\n",
    "        cPickle.dump(enc_test_new, fOut, -1)\n",
    "else:\n",
    "    with gzip.open(fname, 'rb') as f:\n",
    "        enc_test_new = cPickle.load(f)\n",
    "        \n",
    "print('> evaluate')\n",
    "evaluate(enc_test_new, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> compute VLAD for test\n",
      "#test: 3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3600/3600 [07:05<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> evaluate\n",
      "Top-1 accuracy: 0.8380555555555556 - mAP: 0.650423440945756\n"
     ]
    }
   ],
   "source": [
    "gamma = 1\n",
    "gmp = True\n",
    "powernorm = True\n",
    "in_test = '/Users/melihekinci/Documents/FAU_Courses/ThirdSemester/Computer Vision/Week 3/ScriptNet-HistoricalWI-2017-binarized/test_new'\n",
    "suffix = '.desc'\n",
    "labels_test = 'icdar17_labels_test.txt'\n",
    "\n",
    "\n",
    "\n",
    "print('> compute VLAD for test')\n",
    "files_test, labels_test = getFiles(in_test, suffix,\n",
    "                                    labels_test)\n",
    "print('#test: {}'.format(len(files_test)))\n",
    "fname = 'enc_test_new_gmp{}.pkl.gz'.format(gamma) if gmp else 'enc_test_new.pkl.gz'\n",
    "if not os.path.exists(fname):\n",
    "    enc_test_new = vlad(files_test, mus_new,powernorm, gamma,gmp)\n",
    "    with gzip.open(fname, 'wb') as fOut:\n",
    "        cPickle.dump(enc_test_new, fOut, -1)\n",
    "else:\n",
    "    with gzip.open(fname, 'rb') as f:\n",
    "        enc_test_new = cPickle.load(f)\n",
    "        \n",
    "print('> evaluate')\n",
    "evaluate(enc_test_new, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> compute VLAD for train\n",
      "#train: 1182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1182/1182 [02:26<00:00,  8.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# Parameters for VLAD computation\n",
    "n_clusters = 100  # Example number of clusters for k-means\n",
    "max_descriptors = 500000  # Example max descriptors for MiniBatchKMeans\n",
    "C = 1000  # Regularization parameter for SVM\n",
    "\n",
    "# Paths for input data\n",
    "in_train = '/Users/melihekinci/Documents/FAU_Courses/ThirdSemester/Computer Vision/Week 3/icdar2017-training-binary/train_new'\n",
    "suffix = '.desc'  # Suffix for your training files\n",
    "labels_train = 'icdar17_labels_train.txt'\n",
    "gmp=True\n",
    "powernorm=False\n",
    "gamma=1\n",
    "\n",
    "# Compute or load the VLAD encodings for training data\n",
    "enc_train_file = 'enc_train_new_gmp{}.pkl.gz'.format(gamma)\n",
    "if not os.path.exists(enc_train_file):\n",
    "    print('> compute VLAD for train')\n",
    "    files_train, labels_train = getFiles(in_train, suffix, labels_train)\n",
    "    print('#train: {}'.format(len(files_train)))\n",
    "    enc_train_new = vlad(files_train, mus_new, powernorm,gamma,gmp)\n",
    "    with gzip.open(enc_train_file, 'wb') as fOut:\n",
    "        cPickle.dump(enc_train_new, fOut, -1)\n",
    "else:\n",
    "    with gzip.open(enc_train_file, 'rb') as f:\n",
    "        enc_train_new = cPickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> compute E-SVM for test\n",
      "> evaluate E-SVM encodings\n",
      "Top-1 accuracy: 0.9033333333333333 - mAP: 0.7775841934326508\n"
     ]
    }
   ],
   "source": [
    "# With parallelized\n",
    "print('> compute E-SVM for test')\n",
    "enc_train_new = np.array(enc_train_new) if isinstance(enc_train_new, list) else enc_train_new\n",
    "enc_test_new = np.array(enc_test_new) if isinstance(enc_test_new, list) else enc_test_new\n",
    "new_encs_test = exemplar_classification_parallel(enc_train_new, enc_test_new,C_value=1000, n_jobs=-1)\n",
    "# Optionally, evaluate the new E-SVM encodings\n",
    "print('> evaluate E-SVM encodings')\n",
    "evaluate(new_encs_test, labels_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# g - PCA whitening and multi-VLAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Retrieve files and labels for test dataset\n",
      "#test: 3600\n",
      "> Retrieve files and labels for train dataset\n",
      "#train: 1182\n",
      "> Generating multiple codebooks from training data\n",
      "Generating codebook 1/5 with seed 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 46.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating codebook 2/5 with seed 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 44.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating codebook 3/5 with seed 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 41.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating codebook 4/5 with seed 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 42.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating codebook 5/5 with seed 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 40.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Compute Multi-VLAD for training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1182/1182 [03:00<00:00,  6.56it/s]\n",
      "100%|██████████| 1182/1182 [02:31<00:00,  7.81it/s]\n",
      "100%|██████████| 1182/1182 [02:23<00:00,  8.26it/s]\n",
      "100%|██████████| 1182/1182 [02:29<00:00,  7.91it/s]\n",
      "100%|██████████| 1182/1182 [02:26<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Apply PCA on training concatenated encodings\n",
      "> Compute Multi-VLAD for test dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3600/3600 [07:08<00:00,  8.40it/s]\n",
      "100%|██████████| 3600/3600 [07:19<00:00,  8.18it/s]\n",
      "100%|██████████| 3600/3600 [07:32<00:00,  7.96it/s]\n",
      "100%|██████████| 3600/3600 [07:16<00:00,  8.25it/s]\n",
      "100%|██████████| 3600/3600 [06:52<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading previously saved reduced test encodings\n",
      "> Evaluate\n",
      "Top-1 accuracy: 0.8958333333333334 - mAP: 0.7729058808820068\n"
     ]
    }
   ],
   "source": [
    "# Main code\n",
    "gamma = 1\n",
    "gmp = True\n",
    "powernorm = True\n",
    "max_descriptors = 50000  # Example value for max descriptors\n",
    "num_clusters = 100  # Number of clusters for k-means\n",
    "num_codebooks = 5  # Number of different codebooks\n",
    "seeds = [0, 1, 2, 3, 4]\n",
    "\n",
    "in_test = '/Users/melihekinci/Documents/FAU_Courses/ThirdSemester/Computer Vision/Week 3/ScriptNet-HistoricalWI-2017-binarized/test_new'\n",
    "suffix = '.desc'\n",
    "labels_test = 'icdar17_labels_test.txt'\n",
    "\n",
    "in_train = '/Users/melihekinci/Documents/FAU_Courses/ThirdSemester/Computer Vision/Week 3/icdar2017-training-binary/train_new'\n",
    "suffix = '.desc'  # Suffix for your training files\n",
    "labels_train = 'icdar17_labels_train.txt'\n",
    "\n",
    "print('> Retrieve files and labels for test dataset')\n",
    "files_test, labels_test = getFiles_v2(in_test, suffix, labels_test)\n",
    "print('#test: {}'.format(len(files_test)))\n",
    "\n",
    "print('> Retrieve files and labels for train dataset')\n",
    "files_train, labels_train = getFiles_v2(in_train, suffix, labels_train)\n",
    "\n",
    "print('#train: {}'.format(len(files_train)))\n",
    "# Generate multiple codebooks using TRAINING data\n",
    "print('> Generating multiple codebooks from training data')\n",
    "codebooks = generate_multiple_codebooks_v2(files_train, num_clusters, num_codebooks, max_descriptors, seeds)\n",
    "\n",
    "# Compute Multi-VLAD for TRAINING data\n",
    "print('> Compute Multi-VLAD for training dataset')\n",
    "multi_vlad_encodings_train = []\n",
    "for mus in codebooks:\n",
    "    enc_train = vlad(files_train, mus, powernorm, gamma, gmp)\n",
    "    multi_vlad_encodings_train.append(enc_train)\n",
    "concatenated_encodings_train = np.concatenate(multi_vlad_encodings_train, axis=1)\n",
    "\n",
    "# Train PCA on TRAINING data encodings\n",
    "print('> Apply PCA on training concatenated encodings')\n",
    "reduced_enc_train, pca_model = apply_pca(concatenated_encodings_train)\n",
    "\n",
    "# Compute Multi-VLAD for TEST data using the same codebooks\n",
    "print('> Compute Multi-VLAD for test dataset')\n",
    "multi_vlad_encodings_test = []\n",
    "for mus in codebooks:\n",
    "    enc_test = vlad(files_test, mus, powernorm, gamma, gmp)\n",
    "    multi_vlad_encodings_test.append(enc_test)\n",
    "concatenated_encodings_test = np.concatenate(multi_vlad_encodings_test, axis=1)\n",
    "\n",
    "# Apply the SAME PCA model to TEST data encodings\n",
    "reduced_enc_test_new = pca_model.transform(concatenated_encodings_test)\n",
    "\n",
    "# Save and/or Evaluate the reduced TEST encodings\n",
    "fname = 'multi_enc_test_new_gmp{}_pca.pkl.gz'.format(gamma) if gmp else 'multi_enc_test_new_pca.pkl.gz'\n",
    "if not os.path.exists(fname):\n",
    "    print('> Saving reduced test encodings')\n",
    "    with gzip.open(fname, 'wb') as fOut:\n",
    "        cPickle.dump(reduced_enc_test_new, fOut, -1)\n",
    "else:\n",
    "    print('> Loading previously saved reduced test encodings')\n",
    "    with gzip.open(fname, 'rb') as f:\n",
    "        reduced_enc_test_new = cPickle.load(f)\n",
    "\n",
    "print('> Evaluate')\n",
    "evaluate(reduced_enc_test_new, labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> compute E-SVM for test\n",
      "> evaluate E-SVM encodings\n",
      "Top-1 accuracy: 0.8313888888888888 - mAP: 0.6537229927617099\n"
     ]
    }
   ],
   "source": [
    "# With parallelized\n",
    "print('> compute E-SVM for test')\n",
    "enc_train_new = np.array(reduced_enc_train) if isinstance(reduced_enc_train, list) else reduced_enc_train\n",
    "enc_test_new = np.array(reduced_enc_test_new) if isinstance(reduced_enc_test_new, list) else reduced_enc_test_new\n",
    "new_encs_test = exemplar_classification_parallel(enc_train_new, enc_test_new,C_value=1000, n_jobs=-1)\n",
    "# Optionally, evaluate the new E-SVM encodings\n",
    "print('> evaluate E-SVM encodings')\n",
    "evaluate(new_encs_test, labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
